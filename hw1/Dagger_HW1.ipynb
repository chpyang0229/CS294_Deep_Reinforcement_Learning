{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAgger.\n",
    "See the code provided in run expert.py to see how to query the expert policy\n",
    "and perform roll-outs in the environment.\n",
    "1. Implement DAgger. See the code provided in run expert.py to see how to query the expert policy\n",
    "and perform roll-outs in the environment.\n",
    "\n",
    "2. Run DAgger and report results on one task in which DAgger can learn a better policy than behavioral\n",
    "cloning. Report your results in the form of a learning curve, plotting the number of DAgger iterations\n",
    "vs. the policyâ€™s mean return, with error bars to show the standard deviation. Include the performance\n",
    "of the expert policy and the behavioral cloning agent on the same plot. In the caption, state which\n",
    "task you used, and any deta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import load_policy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import tf_util\n",
    "import tqdm\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Lambda\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "env_name = \"Reacher-v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters setting\n",
    "def get_training_opts():\n",
    "    return dict(validation_split=0.1,\n",
    "                batch_size=256,\n",
    "                nb_epoch=50,\n",
    "                verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def regularized_model(num_inputs, num_outputs):\n",
    "    from keras.regularizers import l2, activity_l2\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=num_inputs, init='normal', activation='relu',W_regularizer=l2(0.01), activity_regularizer=activity_l2(0.01),b_regularizer=l2(0.01)))\n",
    "    model.add(Dense(64, input_dim=num_inputs, init='normal', activation='relu',W_regularizer=l2(0.01), activity_regularizer=activity_l2(0.01),b_regularizer=l2(0.01)))\n",
    "    model.add(Dense(num_outputs, init='normal',W_regularizer=l2(0.01), activity_regularizer=activity_l2(0.01),b_regularizer=l2(0.01)))\n",
    "    \n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    return model\n",
    "    \n",
    "def wide_model(num_inputs, num_outputs):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_dim=num_inputs, init='normal', activation='relu'))\n",
    "    model.add(Dense(num_outputs, init='normal'))\n",
    "\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "def get_trainned_model(env):\n",
    "    observations_dim = env.observation_space.shape[0]\n",
    "    actions_dim = env.action_space.shape[0]\n",
    "    model=wide_model(observations_dim, actions_dim)\n",
    "    \n",
    "    print('get_trainned_model completed')\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_data_of_expert_policy(policy_fn ,env, num_rollouts, render):\n",
    "    print(\"begin get data\")\n",
    "    with tf.Session():\n",
    "        tf.variables_initializer\n",
    "        max_steps = env.spec.tags.get('wrapper_config.TimeLimit.max_episode_steps')\n",
    "        print (\"Total rollouts for building policy: \", num_rollouts)\n",
    "        returns = []\n",
    "        observations = []\n",
    "        actions = []\n",
    "        steps_numbers = []\n",
    "    \n",
    "    \n",
    "        for i in (range(num_rollouts)):\n",
    "            obs = env.reset()\n",
    "            done = False\n",
    "            totalr = 0.\n",
    "            steps = 0\n",
    "            while not done:\n",
    "                action = policy_fn(obs[None,:])\n",
    "                observations.append(obs)\n",
    "                actions.append(action)\n",
    "                obs, r, done, _ = env.step(action)\n",
    "                totalr += r\n",
    "                steps += 1\n",
    "                if render:\n",
    "                    env.render()\n",
    "                if steps >= max_steps:\n",
    "                    break\n",
    "            steps_numbers.append(steps)\n",
    "            returns.append(totalr)\n",
    "\n",
    "        expert_data = {'observations': np.array(observations),\n",
    "                   'actions': np.array(actions),\n",
    "                   'returns': np.array(returns),\n",
    "                   'steps': np.array(steps_numbers)}\n",
    "\n",
    "\n",
    "    return expert_data\n",
    "\n",
    "\n",
    "\n",
    "def load_policy_fn(env_name):\n",
    "    print('Gathering expert data')\n",
    "    print('loading and building expert policy')\n",
    "    policy_fname = 'experts/{}.pkl'.format(env_name)\n",
    "    policy_fn = load_policy.load_policy(policy_fname)\n",
    "    print('loaded and built')\n",
    "    return policy_fn\n",
    "\n",
    "\n",
    "def run_trained_model(model, env, rollouts=100, render=False):\n",
    "    max_steps = env.spec.tags.get('wrapper_config.TimeLimit.max_episode_steps')\n",
    "    returns = []\n",
    "    observations = []\n",
    "    actions = []\n",
    "    steps_numbers = []\n",
    "\n",
    "    for i in range(rollouts):\n",
    "        obs = env.reset()\n",
    "        done = False\n",
    "        totalr = 0.\n",
    "        steps = 0\n",
    "        while not done:\n",
    "            action = model.predict(obs[None, :])\n",
    "            observations.append(obs)\n",
    "            actions.append(action)\n",
    "            obs, r, done, _ = env.step(action)\n",
    "            totalr += r\n",
    "            steps += 1\n",
    "            if render:\n",
    "                env.render()\n",
    "            if steps >= max_steps:\n",
    "                break\n",
    "        steps_numbers.append(steps)\n",
    "        returns.append(totalr)  \n",
    "        \n",
    "    return {'observations': np.array(observations),\n",
    "            'actions': np.array(actions),\n",
    "            'returns': np.array(returns),\n",
    "            'steps': np.array(steps_numbers)}\n",
    "\n",
    "\n",
    "\n",
    "def run_expert_on_observations(observations, policy_fn):\n",
    "    with tf.Session():\n",
    "        tf.variables_initializer\n",
    "        actions=[]\n",
    "        \n",
    "        for obs in observations:\n",
    "            action = policy_fn(obs[None,:])\n",
    "            actions.append(action)\n",
    "    return np.array(actions)\n",
    "\n",
    "def get_performance_stat(data):\n",
    "    mean=data['returns'].mean()\n",
    "    std=data['returns'].std()\n",
    "    x=data['steps']\n",
    "    \n",
    "    return pd.Series({\n",
    "        'mean reward': mean,\n",
    "        'std reward': std\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dagger\n",
    "Algorithm in Dagger:\n",
    "- 1) train cloned policy pi(u_t, o_t) from expert data\n",
    "- 2) run pi(u_t, o_t) to get data set D_pi={o_1,...o_M}\n",
    "- 3) Ask human to label D_pi with action\n",
    "- 4) Aggregate the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "env_name = \"Humanoid-v1\"\n",
    "num_rollouts=6\n",
    "render=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-02-18 19:56:53,101] Making new env: Humanoid-v1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gathering expert data\n",
      "loading and building expert policy\n",
      "obs (1, 376) (1, 376)\n",
      "loaded and built\n",
      "begin get data\n",
      "Total rollouts for building policy:  6\n",
      "get_trainned_model completed\n",
      "Train on 5400 samples, validate on 600 samples\n",
      "Epoch 1/50\n",
      "0s - loss: 78.8131 - val_loss: 15.3881\n",
      "Epoch 2/50\n",
      "0s - loss: 7.8037 - val_loss: 3.6206\n",
      "Epoch 3/50\n",
      "0s - loss: 2.8294 - val_loss: 1.9462\n",
      "Epoch 4/50\n",
      "0s - loss: 1.7683 - val_loss: 1.3788\n",
      "Epoch 5/50\n",
      "0s - loss: 1.3304 - val_loss: 1.1202\n",
      "Epoch 6/50\n",
      "0s - loss: 1.1159 - val_loss: 0.9666\n",
      "Epoch 7/50\n",
      "0s - loss: 0.9442 - val_loss: 0.8587\n",
      "Epoch 8/50\n",
      "0s - loss: 0.8237 - val_loss: 0.7585\n",
      "Epoch 9/50\n",
      "0s - loss: 0.7307 - val_loss: 0.6957\n",
      "Epoch 10/50\n",
      "0s - loss: 0.6644 - val_loss: 0.6353\n",
      "Epoch 11/50\n",
      "0s - loss: 0.5993 - val_loss: 0.5870\n",
      "Epoch 12/50\n",
      "0s - loss: 0.5549 - val_loss: 0.5747\n",
      "Epoch 13/50\n",
      "0s - loss: 0.5385 - val_loss: 0.5210\n",
      "Epoch 14/50\n",
      "0s - loss: 0.4773 - val_loss: 0.4674\n",
      "Epoch 15/50\n",
      "0s - loss: 0.4382 - val_loss: 0.4374\n",
      "Epoch 16/50\n",
      "0s - loss: 0.4105 - val_loss: 0.4149\n",
      "Epoch 17/50\n",
      "0s - loss: 0.3904 - val_loss: 0.4017\n",
      "Epoch 18/50\n",
      "0s - loss: 0.3690 - val_loss: 0.3854\n",
      "Epoch 19/50\n",
      "0s - loss: 0.3608 - val_loss: 0.3624\n",
      "Epoch 20/50\n",
      "0s - loss: 0.3359 - val_loss: 0.3551\n",
      "Epoch 21/50\n",
      "0s - loss: 0.3242 - val_loss: 0.3423\n",
      "Epoch 22/50\n",
      "0s - loss: 0.3055 - val_loss: 0.3697\n",
      "Epoch 23/50\n",
      "0s - loss: 0.3163 - val_loss: 0.3334\n",
      "Epoch 24/50\n",
      "0s - loss: 0.3069 - val_loss: 0.3220\n",
      "Epoch 25/50\n",
      "0s - loss: 0.2805 - val_loss: 0.2942\n",
      "Epoch 26/50\n",
      "0s - loss: 0.2610 - val_loss: 0.2941\n",
      "Epoch 27/50\n",
      "0s - loss: 0.2507 - val_loss: 0.2765\n",
      "Epoch 28/50\n",
      "0s - loss: 0.2430 - val_loss: 0.2742\n",
      "Epoch 29/50\n",
      "0s - loss: 0.2470 - val_loss: 0.2861\n",
      "Epoch 30/50\n",
      "0s - loss: 0.2548 - val_loss: 0.2770\n",
      "Epoch 31/50\n",
      "0s - loss: 0.2287 - val_loss: 0.2738\n",
      "Epoch 32/50\n",
      "0s - loss: 0.2258 - val_loss: 0.2667\n",
      "Epoch 33/50\n",
      "0s - loss: 0.2144 - val_loss: 0.2442\n",
      "Epoch 34/50\n",
      "0s - loss: 0.2061 - val_loss: 0.2454\n",
      "Epoch 35/50\n",
      "0s - loss: 0.2079 - val_loss: 0.2370\n",
      "Epoch 36/50\n",
      "0s - loss: 0.1987 - val_loss: 0.2433\n",
      "Epoch 37/50\n",
      "0s - loss: 0.2017 - val_loss: 0.2298\n",
      "Epoch 38/50\n",
      "0s - loss: 0.1859 - val_loss: 0.2188\n",
      "Epoch 39/50\n",
      "0s - loss: 0.1827 - val_loss: 0.2212\n",
      "Epoch 40/50\n",
      "0s - loss: 0.1846 - val_loss: 0.2258\n",
      "Epoch 41/50\n",
      "0s - loss: 0.1795 - val_loss: 0.2262\n",
      "Epoch 42/50\n",
      "0s - loss: 0.1813 - val_loss: 0.2089\n",
      "Epoch 43/50\n",
      "0s - loss: 0.1671 - val_loss: 0.2084\n",
      "Epoch 44/50\n",
      "0s - loss: 0.1626 - val_loss: 0.2029\n",
      "Epoch 45/50\n",
      "0s - loss: 0.1628 - val_loss: 0.1981\n",
      "Epoch 46/50\n",
      "0s - loss: 0.1622 - val_loss: 0.1943\n",
      "Epoch 47/50\n",
      "0s - loss: 0.1562 - val_loss: 0.1964\n",
      "Epoch 48/50\n",
      "0s - loss: 0.1652 - val_loss: 0.2034\n",
      "Epoch 49/50\n",
      "0s - loss: 0.1606 - val_loss: 0.1947\n",
      "Epoch 50/50\n",
      "0s - loss: 0.1488 - val_loss: 0.1870\n",
      "get_trainned_model completed\n",
      "Train on 10222 samples, validate on 1136 samples\n",
      "Epoch 1/50\n",
      "0s - loss: 49.8431 - val_loss: 5.8710\n",
      "Epoch 2/50\n",
      "0s - loss: 3.9508 - val_loss: 2.4926\n",
      "Epoch 3/50\n",
      "0s - loss: 2.1905 - val_loss: 1.7348\n",
      "Epoch 4/50\n",
      "0s - loss: 1.5934 - val_loss: 1.3531\n",
      "Epoch 5/50\n",
      "0s - loss: 1.2523 - val_loss: 1.1143\n",
      "Epoch 6/50\n",
      "0s - loss: 1.0367 - val_loss: 0.9478\n",
      "Epoch 7/50\n",
      "0s - loss: 0.8824 - val_loss: 0.8357\n",
      "Epoch 8/50\n",
      "0s - loss: 0.7755 - val_loss: 0.7458\n",
      "Epoch 9/50\n",
      "0s - loss: 0.6928 - val_loss: 0.6839\n",
      "Epoch 10/50\n",
      "0s - loss: 0.6305 - val_loss: 0.6258\n",
      "Epoch 11/50\n",
      "0s - loss: 0.5843 - val_loss: 0.5852\n",
      "Epoch 12/50\n",
      "0s - loss: 0.5404 - val_loss: 0.5492\n",
      "Epoch 13/50\n",
      "0s - loss: 0.5262 - val_loss: 0.5230\n",
      "Epoch 14/50\n",
      "0s - loss: 0.5015 - val_loss: 0.4885\n",
      "Epoch 15/50\n",
      "0s - loss: 0.4460 - val_loss: 0.4658\n",
      "Epoch 16/50\n",
      "0s - loss: 0.4150 - val_loss: 0.4432\n",
      "Epoch 17/50\n",
      "0s - loss: 0.4011 - val_loss: 0.4238\n",
      "Epoch 18/50\n",
      "0s - loss: 0.3794 - val_loss: 0.4097\n",
      "Epoch 19/50\n",
      "0s - loss: 0.3605 - val_loss: 0.3962\n",
      "Epoch 20/50\n",
      "0s - loss: 0.3490 - val_loss: 0.3795\n",
      "Epoch 21/50\n",
      "0s - loss: 0.3323 - val_loss: 0.3723\n",
      "Epoch 22/50\n",
      "0s - loss: 0.3238 - val_loss: 0.3575\n",
      "Epoch 23/50\n",
      "0s - loss: 0.3145 - val_loss: 0.3543\n",
      "Epoch 24/50\n",
      "0s - loss: 0.3062 - val_loss: 0.3412\n",
      "Epoch 25/50\n",
      "0s - loss: 0.2945 - val_loss: 0.3298\n",
      "Epoch 26/50\n",
      "0s - loss: 0.2879 - val_loss: 0.3220\n",
      "Epoch 27/50\n",
      "0s - loss: 0.2764 - val_loss: 0.3126\n",
      "Epoch 28/50\n",
      "0s - loss: 0.2648 - val_loss: 0.3074\n",
      "Epoch 29/50\n",
      "0s - loss: 0.2532 - val_loss: 0.2960\n",
      "Epoch 30/50\n",
      "0s - loss: 0.2499 - val_loss: 0.2915\n",
      "Epoch 31/50\n",
      "0s - loss: 0.2570 - val_loss: 0.2867\n",
      "Epoch 32/50\n",
      "0s - loss: 0.2364 - val_loss: 0.2825\n",
      "Epoch 33/50\n",
      "0s - loss: 0.2289 - val_loss: 0.2703\n",
      "Epoch 34/50\n",
      "0s - loss: 0.2231 - val_loss: 0.2717\n",
      "Epoch 35/50\n",
      "0s - loss: 0.2209 - val_loss: 0.2623\n",
      "Epoch 36/50\n",
      "0s - loss: 0.2174 - val_loss: 0.2663\n",
      "Epoch 37/50\n",
      "0s - loss: 0.2237 - val_loss: 0.2534\n",
      "Epoch 38/50\n",
      "0s - loss: 0.2160 - val_loss: 0.2509\n",
      "Epoch 39/50\n",
      "0s - loss: 0.2117 - val_loss: 0.2460\n",
      "Epoch 40/50\n",
      "0s - loss: 0.2067 - val_loss: 0.2492\n",
      "Epoch 41/50\n",
      "0s - loss: 0.1996 - val_loss: 0.2426\n",
      "Epoch 42/50\n",
      "0s - loss: 0.2074 - val_loss: 0.2410\n",
      "Epoch 43/50\n",
      "0s - loss: 0.2070 - val_loss: 0.2392\n",
      "Epoch 44/50\n",
      "0s - loss: 0.2024 - val_loss: 0.2338\n",
      "Epoch 45/50\n",
      "0s - loss: 0.2126 - val_loss: 0.2378\n",
      "Epoch 46/50\n",
      "0s - loss: 0.1951 - val_loss: 0.2264\n",
      "Epoch 47/50\n",
      "0s - loss: 0.1966 - val_loss: 0.2203\n",
      "Epoch 48/50\n",
      "0s - loss: 0.1836 - val_loss: 0.2206\n",
      "Epoch 49/50\n",
      "0s - loss: 0.1791 - val_loss: 0.2147\n",
      "Epoch 50/50\n",
      "0s - loss: 0.1736 - val_loss: 0.2141\n",
      "get_trainned_model completed\n",
      "Train on 15286 samples, validate on 1699 samples\n",
      "Epoch 1/50\n",
      "0s - loss: 36.4217 - val_loss: 4.1008\n",
      "Epoch 2/50\n",
      "0s - loss: 2.8134 - val_loss: 2.1267\n",
      "Epoch 3/50\n",
      "0s - loss: 1.6947 - val_loss: 1.4997\n",
      "Epoch 4/50\n",
      "0s - loss: 1.2352 - val_loss: 1.1904\n",
      "Epoch 5/50\n",
      "0s - loss: 0.9923 - val_loss: 0.9995\n",
      "Epoch 6/50\n",
      "0s - loss: 0.8430 - val_loss: 0.8664\n",
      "Epoch 7/50\n",
      "0s - loss: 0.7252 - val_loss: 0.7737\n",
      "Epoch 8/50\n",
      "0s - loss: 0.6468 - val_loss: 0.7016\n",
      "Epoch 9/50\n",
      "0s - loss: 0.5946 - val_loss: 0.6372\n",
      "Epoch 10/50\n",
      "0s - loss: 0.5186 - val_loss: 0.5796\n",
      "Epoch 11/50\n",
      "0s - loss: 0.4706 - val_loss: 0.5431\n",
      "Epoch 12/50\n",
      "0s - loss: 0.4417 - val_loss: 0.5074\n",
      "Epoch 13/50\n",
      "0s - loss: 0.4140 - val_loss: 0.4743\n",
      "Epoch 14/50\n",
      "0s - loss: 0.3827 - val_loss: 0.4409\n",
      "Epoch 15/50\n",
      "0s - loss: 0.3612 - val_loss: 0.4258\n",
      "Epoch 16/50\n",
      "0s - loss: 0.3428 - val_loss: 0.4024\n",
      "Epoch 17/50\n",
      "0s - loss: 0.3315 - val_loss: 0.3865\n",
      "Epoch 18/50\n",
      "0s - loss: 0.3227 - val_loss: 0.3759\n",
      "Epoch 19/50\n",
      "0s - loss: 0.3050 - val_loss: 0.3567\n",
      "Epoch 20/50\n",
      "0s - loss: 0.3020 - val_loss: 0.3456\n",
      "Epoch 21/50\n",
      "0s - loss: 0.2868 - val_loss: 0.3399\n",
      "Epoch 22/50\n",
      "0s - loss: 0.2706 - val_loss: 0.3232\n",
      "Epoch 23/50\n",
      "0s - loss: 0.2780 - val_loss: 0.3221\n",
      "Epoch 24/50\n",
      "0s - loss: 0.2595 - val_loss: 0.3018\n",
      "Epoch 25/50\n",
      "0s - loss: 0.2647 - val_loss: 0.3043\n",
      "Epoch 26/50\n",
      "0s - loss: 0.2910 - val_loss: 0.3127\n",
      "Epoch 27/50\n",
      "0s - loss: 0.2898 - val_loss: 0.2889\n",
      "Epoch 28/50\n",
      "0s - loss: 0.2296 - val_loss: 0.2710\n",
      "Epoch 29/50\n",
      "0s - loss: 0.2170 - val_loss: 0.2671\n",
      "Epoch 30/50\n",
      "0s - loss: 0.2194 - val_loss: 0.2630\n",
      "Epoch 31/50\n",
      "0s - loss: 0.2118 - val_loss: 0.2670\n",
      "Epoch 32/50\n",
      "0s - loss: 0.1985 - val_loss: 0.2465\n",
      "Epoch 33/50\n",
      "0s - loss: 0.1988 - val_loss: 0.2586\n",
      "Epoch 34/50\n",
      "0s - loss: 0.2031 - val_loss: 0.2495\n",
      "Epoch 35/50\n",
      "0s - loss: 0.1905 - val_loss: 0.2368\n",
      "Epoch 36/50\n",
      "0s - loss: 0.1998 - val_loss: 0.2925\n",
      "Epoch 37/50\n",
      "0s - loss: 0.1909 - val_loss: 0.2346\n",
      "Epoch 38/50\n",
      "0s - loss: 0.1773 - val_loss: 0.2220\n",
      "Epoch 39/50\n",
      "0s - loss: 0.1732 - val_loss: 0.2246\n",
      "Epoch 40/50\n",
      "0s - loss: 0.1758 - val_loss: 0.2227\n",
      "Epoch 41/50\n",
      "0s - loss: 0.1769 - val_loss: 0.2259\n",
      "Epoch 42/50\n",
      "0s - loss: 0.1799 - val_loss: 0.2156\n",
      "Epoch 43/50\n",
      "0s - loss: 0.1756 - val_loss: 0.2133\n",
      "Epoch 44/50\n",
      "0s - loss: 0.1680 - val_loss: 0.2116\n",
      "Epoch 45/50\n",
      "0s - loss: 0.1784 - val_loss: 0.2221\n",
      "Epoch 46/50\n",
      "0s - loss: 0.1921 - val_loss: 0.1989\n",
      "Epoch 47/50\n",
      "0s - loss: 0.1659 - val_loss: 0.2087\n",
      "Epoch 48/50\n",
      "0s - loss: 0.1616 - val_loss: 0.1984\n",
      "Epoch 49/50\n",
      "0s - loss: 0.1561 - val_loss: 0.1917\n",
      "Epoch 50/50\n",
      "0s - loss: 0.1560 - val_loss: 0.2047\n",
      "get_trainned_model completed\n",
      "Train on 24979 samples, validate on 2776 samples\n",
      "Epoch 1/50\n",
      "0s - loss: 16.5321 - val_loss: 2.3113\n",
      "Epoch 2/50\n",
      "0s - loss: 1.7401 - val_loss: 1.3128\n",
      "Epoch 3/50\n",
      "0s - loss: 1.1204 - val_loss: 0.9576\n",
      "Epoch 4/50\n",
      "0s - loss: 0.8599 - val_loss: 0.7762\n",
      "Epoch 5/50\n",
      "0s - loss: 0.7036 - val_loss: 0.6734\n",
      "Epoch 6/50\n",
      "0s - loss: 0.6085 - val_loss: 0.5858\n",
      "Epoch 7/50\n",
      "0s - loss: 0.5477 - val_loss: 0.5224\n",
      "Epoch 8/50\n",
      "0s - loss: 0.4947 - val_loss: 0.5226\n",
      "Epoch 9/50\n",
      "0s - loss: 0.4432 - val_loss: 0.4224\n",
      "Epoch 10/50\n",
      "0s - loss: 0.4045 - val_loss: 0.4080\n",
      "Epoch 11/50\n",
      "0s - loss: 0.3741 - val_loss: 0.3823\n",
      "Epoch 12/50\n",
      "0s - loss: 0.3749 - val_loss: 0.3726\n",
      "Epoch 13/50\n",
      "0s - loss: 0.3418 - val_loss: 0.3501\n",
      "Epoch 14/50\n",
      "0s - loss: 0.3500 - val_loss: 0.3449\n",
      "Epoch 15/50\n",
      "0s - loss: 0.3092 - val_loss: 0.3047\n",
      "Epoch 16/50\n",
      "0s - loss: 0.2841 - val_loss: 0.2956\n",
      "Epoch 17/50\n",
      "0s - loss: 0.2675 - val_loss: 0.2826\n",
      "Epoch 18/50\n",
      "0s - loss: 0.2585 - val_loss: 0.2650\n",
      "Epoch 19/50\n",
      "0s - loss: 0.2465 - val_loss: 0.2658\n",
      "Epoch 20/50\n",
      "0s - loss: 0.2427 - val_loss: 0.2678\n",
      "Epoch 21/50\n",
      "0s - loss: 0.2402 - val_loss: 0.2438\n",
      "Epoch 22/50\n",
      "0s - loss: 0.2290 - val_loss: 0.2651\n",
      "Epoch 23/50\n",
      "0s - loss: 0.2195 - val_loss: 0.2455\n",
      "Epoch 24/50\n",
      "0s - loss: 0.2188 - val_loss: 0.2503\n",
      "Epoch 25/50\n",
      "0s - loss: 0.2156 - val_loss: 0.2266\n",
      "Epoch 26/50\n",
      "0s - loss: 0.2015 - val_loss: 0.2221\n",
      "Epoch 27/50\n",
      "0s - loss: 0.1994 - val_loss: 0.2153\n",
      "Epoch 28/50\n",
      "0s - loss: 0.1995 - val_loss: 0.2390\n",
      "Epoch 29/50\n",
      "0s - loss: 0.1938 - val_loss: 0.2092\n",
      "Epoch 30/50\n",
      "0s - loss: 0.1971 - val_loss: 0.2035\n",
      "Epoch 31/50\n",
      "0s - loss: 0.1894 - val_loss: 0.2053\n",
      "Epoch 32/50\n",
      "0s - loss: 0.1839 - val_loss: 0.1990\n",
      "Epoch 33/50\n",
      "0s - loss: 0.1749 - val_loss: 0.1826\n",
      "Epoch 34/50\n",
      "0s - loss: 0.1752 - val_loss: 0.1918\n",
      "Epoch 35/50\n",
      "0s - loss: 0.1681 - val_loss: 0.2041\n",
      "Epoch 36/50\n",
      "0s - loss: 0.1705 - val_loss: 0.1815\n",
      "Epoch 37/50\n",
      "0s - loss: 0.1761 - val_loss: 0.1915\n",
      "Epoch 38/50\n",
      "0s - loss: 0.1635 - val_loss: 0.1834\n",
      "Epoch 39/50\n",
      "0s - loss: 0.1639 - val_loss: 0.1829\n",
      "Epoch 40/50\n",
      "0s - loss: 0.1645 - val_loss: 0.1902\n",
      "Epoch 41/50\n",
      "0s - loss: 0.1597 - val_loss: 0.1643\n",
      "Epoch 42/50\n",
      "0s - loss: 0.1557 - val_loss: 0.1757\n",
      "Epoch 43/50\n",
      "0s - loss: 0.1541 - val_loss: 0.1716\n",
      "Epoch 44/50\n",
      "0s - loss: 0.1556 - val_loss: 0.1779\n",
      "Epoch 45/50\n",
      "0s - loss: 0.1692 - val_loss: 0.1895\n",
      "Epoch 46/50\n",
      "0s - loss: 0.1538 - val_loss: 0.1958\n",
      "Epoch 47/50\n",
      "0s - loss: 0.1601 - val_loss: 0.1814\n",
      "Epoch 48/50\n",
      "0s - loss: 0.1531 - val_loss: 0.1579\n",
      "Epoch 49/50\n",
      "0s - loss: 0.1446 - val_loss: 0.1509\n",
      "Epoch 50/50\n",
      "0s - loss: 0.1505 - val_loss: 0.1712\n",
      "get_trainned_model completed\n",
      "Train on 46845 samples, validate on 5206 samples\n",
      "Epoch 1/50\n",
      "1s - loss: 6.8729 - val_loss: 1.3743\n",
      "Epoch 2/50\n",
      "0s - loss: 1.0304 - val_loss: 0.8674\n",
      "Epoch 3/50\n",
      "0s - loss: 0.7197 - val_loss: 0.6788\n",
      "Epoch 4/50\n",
      "0s - loss: 0.5798 - val_loss: 0.5573\n",
      "Epoch 5/50\n",
      "0s - loss: 0.4914 - val_loss: 0.4855\n",
      "Epoch 6/50\n",
      "0s - loss: 0.4402 - val_loss: 0.4436\n",
      "Epoch 7/50\n",
      "0s - loss: 0.3925 - val_loss: 0.3980\n",
      "Epoch 8/50\n",
      "0s - loss: 0.3522 - val_loss: 0.3727\n",
      "Epoch 9/50\n",
      "0s - loss: 0.3333 - val_loss: 0.3488\n",
      "Epoch 10/50\n",
      "0s - loss: 0.3119 - val_loss: 0.3208\n",
      "Epoch 11/50\n",
      "0s - loss: 0.3054 - val_loss: 0.3265\n",
      "Epoch 12/50\n",
      "0s - loss: 0.2878 - val_loss: 0.3118\n",
      "Epoch 13/50\n",
      "0s - loss: 0.2716 - val_loss: 0.2721\n",
      "Epoch 14/50\n",
      "0s - loss: 0.2584 - val_loss: 0.2883\n",
      "Epoch 15/50\n",
      "0s - loss: 0.2505 - val_loss: 0.2768\n",
      "Epoch 16/50\n",
      "0s - loss: 0.2391 - val_loss: 0.2503\n",
      "Epoch 17/50\n",
      "0s - loss: 0.2331 - val_loss: 0.2353\n",
      "Epoch 18/50\n",
      "0s - loss: 0.2248 - val_loss: 0.2737\n",
      "Epoch 19/50\n",
      "0s - loss: 0.2212 - val_loss: 0.2182\n",
      "Epoch 20/50\n",
      "0s - loss: 0.2252 - val_loss: 0.2203\n",
      "Epoch 21/50\n",
      "0s - loss: 0.2076 - val_loss: 0.2115\n",
      "Epoch 22/50\n",
      "0s - loss: 0.1972 - val_loss: 0.2111\n",
      "Epoch 23/50\n",
      "0s - loss: 0.1958 - val_loss: 0.2033\n",
      "Epoch 24/50\n",
      "0s - loss: 0.1896 - val_loss: 0.1858\n",
      "Epoch 25/50\n",
      "0s - loss: 0.1811 - val_loss: 0.1953\n",
      "Epoch 26/50\n",
      "0s - loss: 0.1849 - val_loss: 0.1970\n",
      "Epoch 27/50\n",
      "0s - loss: 0.1779 - val_loss: 0.1894\n",
      "Epoch 28/50\n",
      "0s - loss: 0.1763 - val_loss: 0.1932\n",
      "Epoch 29/50\n",
      "0s - loss: 0.1712 - val_loss: 0.2071\n",
      "Epoch 30/50\n",
      "0s - loss: 0.1678 - val_loss: 0.1752\n",
      "Epoch 31/50\n",
      "0s - loss: 0.1617 - val_loss: 0.1787\n",
      "Epoch 32/50\n",
      "0s - loss: 0.1739 - val_loss: 0.1789\n",
      "Epoch 33/50\n",
      "0s - loss: 0.1544 - val_loss: 0.1671\n",
      "Epoch 34/50\n",
      "0s - loss: 0.1546 - val_loss: 0.1639\n",
      "Epoch 35/50\n",
      "0s - loss: 0.1506 - val_loss: 0.1580\n",
      "Epoch 36/50\n",
      "0s - loss: 0.1490 - val_loss: 0.1664\n",
      "Epoch 37/50\n",
      "0s - loss: 0.1459 - val_loss: 0.1587\n",
      "Epoch 38/50\n",
      "0s - loss: 0.1434 - val_loss: 0.1487\n",
      "Epoch 39/50\n",
      "0s - loss: 0.1413 - val_loss: 0.1526\n",
      "Epoch 40/50\n",
      "0s - loss: 0.1376 - val_loss: 0.1532\n",
      "Epoch 41/50\n",
      "0s - loss: 0.1392 - val_loss: 0.1520\n",
      "Epoch 42/50\n",
      "0s - loss: 0.1351 - val_loss: 0.1460\n",
      "Epoch 43/50\n",
      "0s - loss: 0.1397 - val_loss: 0.1557\n",
      "Epoch 44/50\n",
      "0s - loss: 0.1330 - val_loss: 0.1505\n",
      "Epoch 45/50\n",
      "0s - loss: 0.1319 - val_loss: 0.1458\n",
      "Epoch 46/50\n",
      "0s - loss: 0.1309 - val_loss: 0.1488\n",
      "Epoch 47/50\n",
      "0s - loss: 0.1308 - val_loss: 0.1398\n",
      "Epoch 48/50\n",
      "0s - loss: 0.1278 - val_loss: 0.1409\n",
      "Epoch 49/50\n",
      "0s - loss: 0.1275 - val_loss: 0.1396\n",
      "Epoch 50/50\n",
      "0s - loss: 0.1243 - val_loss: 0.1400\n"
     ]
    }
   ],
   "source": [
    "policy_fn=load_policy_fn(env_name)\n",
    "\n",
    "#  0) Get the params for the training model\n",
    "training_params=get_training_opts()\n",
    "#  Get the training data for the training model\n",
    "env=gym.make(env_name)\n",
    "data=get_data_of_expert_policy(policy_fn, env, num_rollouts, render)\n",
    "\n",
    "x=data['observations']\n",
    "actions_dim = env.action_space.shape[0]\n",
    "\n",
    "y=data['actions'].reshape(-1, actions_dim)\n",
    "stats={}\n",
    "rewards={}\n",
    "\n",
    "for i in range(5):\n",
    "    # 1) Train the model\n",
    "    model=get_trainned_model(env)\n",
    "\n",
    "    x, y=shuffle(x, y)\n",
    "\n",
    "    model.fit(x,y,**training_params)\n",
    "\n",
    "    # 2) Get the generated data\n",
    "    data_generated=run_trained_model(model, env, render=False)\n",
    "    stats[i]=get_performance_stat(data_generated)\n",
    "    rewards[i]=data_generated['returns']\n",
    "    x_new=data_generated['observations']\n",
    "\n",
    "    # 3) Get the label with generated data\n",
    "    y_new=run_expert_on_observations(x_new, policy_fn)\n",
    "\n",
    "    # 4) Aggregate the data \n",
    "    x=np.append(x, x_new, axis=0)\n",
    "    y=np.append(y,y_new.reshape(-1, actions_dim), axis=0)\n",
    "# Test the model performance with aggregated dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save the performance of  training  model without using the DAgger data \n",
    "df=pd.DataFrame(stats).T\n",
    "pickle_name='data/{}-DAgger-rewards.p'.format(env_name)\n",
    "df.index.name='iterations'\n",
    "df.to_csv('data/{}-DAgger.csv'.format(env_name))\n",
    "pickle.dump(rewards, open(pickle_name,'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show the Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEVCAYAAAAo63jjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXohTVtgYAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8eb8a5b0f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pickle_name='data/{}-DAgger-rewards.p'.format(env_name)\n",
    "rewards=pickle.load(open(pickle_name,'rb'))\n",
    "\n",
    "pickle_name='data/{}-their.p'.format(env_name)\n",
    "their_data=pickle.load(open(pickle_name,'rb'))['returns']\n",
    "\n",
    "df=pd.DataFrame(rewards)\n",
    "\n",
    "sns.tsplot(data=their_data, color='red', linestyle='--')\n",
    "sns.tsplot(time=df.columns, data=df.values, color='blue', linestyle='-')\n",
    "plt.ylabel(\"Mean reward\")\n",
    "plt.xlabel(\"Number of iterations (DAgger)\")\n",
    "plt.title(\"{} - DAgger performance\".format(env_name))\n",
    "\n",
    "import matplotlib.patches as mpatches\n",
    "plt.legend(handles=[\n",
    "    mpatches.Patch(color='blue', label='DAgger policy'),\n",
    "    mpatches.Patch(color='red', label='expert policy'),\n",
    "], loc='lower right')\n",
    "\n",
    "plt.savefig(\"dagger-{}.png\".format(env_name),format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
